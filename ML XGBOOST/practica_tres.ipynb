{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este problema decidimos como equipo utilizar modelo un de aprendizaje supervisado. Concretamente un modelo de regresión dado que el valor a predecir es decir, el CCS es un valor continuo y no tendría sentido crear clasificaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos la práctica importando los datos de public_test.csv y public_train.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ccs</th>\n",
       "      <th>adduct</th>\n",
       "      <th>desc_1</th>\n",
       "      <th>desc_2</th>\n",
       "      <th>desc_3</th>\n",
       "      <th>desc_4</th>\n",
       "      <th>desc_5</th>\n",
       "      <th>desc_6</th>\n",
       "      <th>desc_7</th>\n",
       "      <th>desc_8</th>\n",
       "      <th>...</th>\n",
       "      <th>fgp_611</th>\n",
       "      <th>fgp_612</th>\n",
       "      <th>fgp_613</th>\n",
       "      <th>fgp_614</th>\n",
       "      <th>fgp_615</th>\n",
       "      <th>fgp_616</th>\n",
       "      <th>fgp_617</th>\n",
       "      <th>fgp_618</th>\n",
       "      <th>fgp_619</th>\n",
       "      <th>fgp_620</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>155.71001</td>\n",
       "      <td>Monomer_[M+H]</td>\n",
       "      <td>-5.27492</td>\n",
       "      <td>420.85751</td>\n",
       "      <td>0.79886</td>\n",
       "      <td>60.68518</td>\n",
       "      <td>0.22702</td>\n",
       "      <td>54.36304</td>\n",
       "      <td>55.73885</td>\n",
       "      <td>8.28095</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179.56000</td>\n",
       "      <td>Monomer_[M-H]</td>\n",
       "      <td>-2.00000</td>\n",
       "      <td>1171.97156</td>\n",
       "      <td>1.13333</td>\n",
       "      <td>121.96276</td>\n",
       "      <td>0.15520</td>\n",
       "      <td>100.45390</td>\n",
       "      <td>97.68512</td>\n",
       "      <td>11.36667</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180.00000</td>\n",
       "      <td>Monomer_[M+Na]</td>\n",
       "      <td>-0.70060</td>\n",
       "      <td>1447.22644</td>\n",
       "      <td>1.30616</td>\n",
       "      <td>141.10509</td>\n",
       "      <td>0.13916</td>\n",
       "      <td>110.47855</td>\n",
       "      <td>108.96603</td>\n",
       "      <td>12.96667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>155.53999</td>\n",
       "      <td>Monomer_[M+Na]</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>479.80600</td>\n",
       "      <td>0.92774</td>\n",
       "      <td>74.90678</td>\n",
       "      <td>0.21166</td>\n",
       "      <td>65.64590</td>\n",
       "      <td>66.68343</td>\n",
       "      <td>6.83333</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>173.50000</td>\n",
       "      <td>Monomer_[M+H]</td>\n",
       "      <td>-1.63669</td>\n",
       "      <td>978.85028</td>\n",
       "      <td>1.24843</td>\n",
       "      <td>112.27611</td>\n",
       "      <td>0.15789</td>\n",
       "      <td>87.88085</td>\n",
       "      <td>89.68015</td>\n",
       "      <td>10.73333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1942 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ccs          adduct   desc_1      desc_2   desc_3     desc_4  \\\n",
       "0  155.71001   Monomer_[M+H] -5.27492   420.85751  0.79886   60.68518   \n",
       "1  179.56000   Monomer_[M-H] -2.00000  1171.97156  1.13333  121.96276   \n",
       "2  180.00000  Monomer_[M+Na] -0.70060  1447.22644  1.30616  141.10509   \n",
       "3  155.53999  Monomer_[M+Na]  0.00000   479.80600  0.92774   74.90678   \n",
       "4  173.50000   Monomer_[M+H] -1.63669   978.85028  1.24843  112.27611   \n",
       "\n",
       "    desc_5     desc_6     desc_7    desc_8  ...  fgp_611  fgp_612  fgp_613  \\\n",
       "0  0.22702   54.36304   55.73885   8.28095  ...        0        0        1   \n",
       "1  0.15520  100.45390   97.68512  11.36667  ...        1        0        0   \n",
       "2  0.13916  110.47855  108.96603  12.96667  ...        0        1        1   \n",
       "3  0.21166   65.64590   66.68343   6.83333  ...        1        0        1   \n",
       "4  0.15789   87.88085   89.68015  10.73333  ...        0        1        0   \n",
       "\n",
       "   fgp_614  fgp_615  fgp_616  fgp_617  fgp_618  fgp_619  fgp_620  \n",
       "0        0        1        1        1        0        1        0  \n",
       "1        1        0        1        0        1        1        0  \n",
       "2        0        1        0        0        0        0        1  \n",
       "3        1        1        0        1        1        0        0  \n",
       "4        1        0        0        1        0        1        0  \n",
       "\n",
       "[5 rows x 1942 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importación de los datos:\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "# /workspaces/Practica-IA-3/public_test.csv\n",
    "# /workspaces/Practica-IA-3/public_train.csv\n",
    "# Dataframe\n",
    "test_data = pd.read_csv(\"public_test.csv\")\n",
    "train_data = pd.read_csv(\"public_train.csv\")\n",
    "test_data.head()\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos un modelo de descenso de gradiente concretamente la implementación de XGBoost que admite resolver tareas de regresión. Por tanto, este funcionará como un modelo de regresión de descenso de gradiente. A continuación se realizará el preprocesamiento de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Preprocesamiento de los datos, en primer lugar ver que pinta tienen los primeros datos:\n",
    "\n",
    "y = train_data[\"ccs\"]\n",
    "x = train_data.drop(columns=[\"ccs\"])\n",
    "\n",
    "numeric_features = x.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = [\"adduct\"]\n",
    "\n",
    "# print(test_data) con el print, se pueden observar algunos valores de NaN, por tanto apicamos imputación:\n",
    "# print(train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo + prepocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def create_preproc_and_model(numeric_features , categorical_features, params):\n",
    "    scaler = StandardScaler()\n",
    "    numeric_imputer = SimpleImputer(strategy=\"mean\")\n",
    "    categorical_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    oh_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", numeric_imputer),\n",
    "        (\"scaler\", scaler)\n",
    "    ])\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", categorical_imputer),\n",
    "        (\"encoder\", oh_encoder)\n",
    "    ])\n",
    "\n",
    "    transformer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numeric_imp', numeric_transformer, numeric_features),\n",
    "            ('categorial_imp', categorical_transformer, categorical_features) \n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Crear modelo XGBoost con los parámetros\n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    \n",
    "    return Pipeline(steps=[\n",
    "        (\"transformer\", transformer),\n",
    "        (\"model\", model)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento + Comprobar mejores parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Mejores parámetros encontrados: {'model__alpha': 0.1, 'model__booster': 'gblinear', 'model__enable_categorical': True, 'model__lambda': 0.7, 'model__learning_rate': 0.03, 'model__n_estimators': 300, 'model__objective': 'reg:squarederror'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "x_train , x_test , y_train , y_test = train_test_split(x , y , test_size=0.2)\n",
    "# Hay que ajustar el modelo y seleccionar el que mejor rendimiento tiene.\n",
    "params = {\n",
    "        \"objective\": [\"reg:squarederror\"],  # Para regresión\n",
    "        \"booster\": [\"gblinear\"],           # Usa modelo lineal\n",
    "        \"alpha\": [0.1],   # Regularización L1 (Lasso)\n",
    "        \"lambda\": [ 0.7 , 0.8 , 0.9],                   # Regularización L2 (Ridge)\n",
    "        \"n_estimators\": [200 , 300],              # Número de árboles que se entrenan\n",
    "        \"learning_rate\": [0.02 , 0.03],           # Conservador vs rápido\n",
    "        \"enable_categorical\": [True]  # SI TIENE COLUMNAS CATEGóRICAS\n",
    "    }\n",
    "pipeline = create_preproc_and_model(numeric_features, categorical_features, params=params)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, \n",
    "                           param_grid={\"model__\" + key: value for key, value in params.items()},  # Añadir \"model__\" antes de cada parámetro\n",
    "                           cv=3,\n",
    "                           scoring='neg_mean_squared_error', \n",
    "                           n_jobs=-1, \n",
    "                           verbose=1)\n",
    "\n",
    "grid_search.fit(x_train , y_train)\n",
    "print(\"Mejores parámetros encontrados:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 118.12900489559534\n",
      "Root Mean Squared Error (RMSE): 10.868716800781744\n",
      "Mean Absolute Error (MAE): 5.905903130023832\n",
      "R² Score: 0.9628629163718576\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "predicciones = best_model.predict(x_test)\n",
    "\n",
    "# Evaluación\n",
    "mse = mean_squared_error(y_test, predicciones)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, predicciones)\n",
    "r2 = r2_score(y_test, predicciones)\n",
    "\n",
    "# Resultados\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"R² Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ya con los parametros fijados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 70.38003294890628\n",
      "Root Mean Squared Error (RMSE): 8.389280836216313\n",
      "Mean Absolute Error (MAE): 5.476769536943677\n",
      "R² Score: 0.9792038141759865\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "x_train , x_test , y_train , y_test = train_test_split(x , y , test_size=0.2)\n",
    "# Hay que ajustar el modelo y seleccionar el que mejor rendimiento tiene.\n",
    "params = {\n",
    "        \"objective\": \"reg:squarederror\",  # Para regresión\n",
    "        \"booster\": \"gblinear\",           # Usa modelo lineal\n",
    "        \"alpha\": 0.1,                    # Regularización L1 (Lasso)\n",
    "        \"lambda\": 0.7,                   # Regularización L2 (Ridge)\n",
    "        \"n_estimators\": 300,             # Número de árboles que se entrenan\n",
    "        \"learning_rate\": 0.03,           # Conservador vs rápido\n",
    "        \"enable_categorical\": True       # SI TIENE COLUMNAS CATEGóRICAS\n",
    "    }\n",
    "pipeline = create_preproc_and_model(numeric_features, categorical_features, params=params)\n",
    "\n",
    "pipeline.fit(x_train , y_train)\n",
    "\n",
    "predicciones = pipeline.predict(x_test)\n",
    "\n",
    "# Evaluación\n",
    "mse = mean_squared_error(y_test, predicciones)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, predicciones)\n",
    "r2 = r2_score(y_test, predicciones)\n",
    "\n",
    "# Resultados\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"R² Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de la salida de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones para test_data:\n",
      "[176.9566  261.0208  228.08781 ... 218.80911 168.30586 279.02972]\n"
     ]
    }
   ],
   "source": [
    "predicciones_test = pipeline.predict(test_data)\n",
    "\n",
    "# Mostrar predicciones\n",
    "print(\"Predicciones para test_data:\")\n",
    "print(predicciones_test)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
